{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8b472b-f3fb-46c2-841f-930a4692697b",
   "metadata": {},
   "source": [
    "# LLMCompiler\n",
    "\n",
    "This notebook shows how to implement [LLMCompiler, by Kim, et. al](https://arxiv.org/abs/2312.04511) in LangGraph.\n",
    "\n",
    "LLMCompiler is an agent architecture designed to **speed up** the execution of agentic tasks by eagerly-executed tasks within a DAG. It also saves costs on redundant token usage by reducing the number of calls to the LLM. Below is an overview of its computational graph:\n",
    "\n",
    "![LLMCompiler Graph](./img/llm-compiler.png)\n",
    "\n",
    "It has 3 main components:\n",
    "\n",
    "1. Planner: stream a DAG of tasks.\n",
    "2. Task Fetching Unit: schedules and executes the tasks as soon as they are executable\n",
    "3. Joiner: Responds to the user or triggers a second plan\n",
    "\n",
    "\n",
    "This notebook walks through each component and shows how to wire them together using LangGraph. The end result will leave a trace [like the following](https://smith.langchain.com/public/218c2677-c719-4147-b0e9-7bc3b5bb2623/r).\n",
    "\n",
    "\n",
    "**First,** install the dependencies, and set up LangSmith for tracing to more easily debug and observe the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16bd5497-35ad-44f2-94d9-19ff39a5ffed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U --quiet langchainhub langchain_openai langsmith langgraph langchain numexpr langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbd6948-e9a3-47ca-89c7-7ac2fc5eca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "\n",
    "def _get_pass(var: str):\n",
    "    if var not in os.environ:\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "# Optional: Debug + trace calls using LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"True\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LLMCompiler\"\n",
    "_get_pass(\"LANGCHAIN_API_KEY\")\n",
    "_get_pass(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61b48ee-8c6f-4863-913a-676f659287de",
   "metadata": {},
   "source": [
    "## Part 1: Tools\n",
    "\n",
    "We'll first define the tools for the agent to use in our demo. We'll give it the class search engine + calculator combo.\n",
    "\n",
    "If you don't want to sign up for tavily, you can replace it with the free [DuckDuckGo](https://python.langchain.com/docs/integrations/tools/ddg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7476bb2-1a51-42f6-b7ae-82a0300bbf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/langgraph/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: LangChain has introduced a method called `with_structured_output` that is available on ChatModels capable of tool calling. You can read more about the method here: https://python.langchain.com/docs/modules/model_io/chat/structured_output/ Please follow our extraction use case documentation for more guidelines on how to do information extraction with LLMs. https://python.langchain.com/docs/use_cases/extraction/. If you notice other issues, please provide feedback here: https://github.com/langchain-ai/langchain/discussions/18154\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Imported from the https://github.com/langchain-ai/langgraph/tree/main/examples/plan-and-execute repo\n",
    "from math_tools import get_math_tool\n",
    "\n",
    "_get_pass(\"TAVILY_API_KEY\")\n",
    "\n",
    "calculate = get_math_tool(ChatOpenAI(model=\"gpt-4o\"))\n",
    "search = TavilySearchResults(\n",
    "    max_results=1,\n",
    "    description='tavily_search_results_json(query=\"the search query\") - a search engine.',\n",
    ")\n",
    "\n",
    "tools = [search, calculate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152eecf3-6bef-4718-af71-a0b3c5a3b009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'37'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate.invoke(\n",
    "    {\n",
    "        \"problem\": \"What's the temp of sf + 5?\",\n",
    "        \"context\": [\"Thet empreature of sf is 32 degrees\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e99a0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA MODEL = video_url='https://www.youtube.com/watch?v=dQw4w9WgXcQ' context=None\n",
      "{'url': 'https://www.youtube.com/watch?v=dQw4w9WgXcQ', 'title': 'Sample Title', 'description': 'Sample description of the video.', 'views': '12345', 'likes': '678', 'dislikes': '90', 'comments': [{'author': 'User1', 'text': 'Sample comment 1'}, {'author': 'User2', 'text': 'Sample comment 2'}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from youtube_tools import get_youtube_parser_tool  # Adjust the import based on your file structure\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Get the youtube_parser tool\n",
    "youtube_parser_tool = get_youtube_parser_tool(llm)\n",
    "\n",
    "# Define the YouTube video URL\n",
    "video_url = \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\"\n",
    "\n",
    "# Call the tool with the video URL\n",
    "result = youtube_parser_tool.func(video_url=video_url)\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15904e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description='tavily_search_results_json(query=\"the search query\") - a search engine.' max_results=1\n",
      "name='math' description='math(problem: str, context: Optional[list[str]]) -> float:\\n - Solves the provided math problem.\\n - `problem` can be either a simple math problem (e.g. \"1 + 3\") or a word problem (e.g. \"how many apples are there if there are 3 apples and 2 apples\").\\n - You cannot calculate multiple expressions in one call. For instance, `math(\\'1 + 3, 2 + 4\\')` does not work. If you need to calculate multiple expressions, you need to call them separately like `math(\\'1 + 3\\')` and then `math(\\'2 + 4\\')`\\n - Minimize the number of `math` actions as much as possible. For instance, instead of calling 2. math(\"what is the 10% of $1\") and then call 3. math(\"$1 + $2\"), you MUST call 2. math(\"what is the 110% of $1\") instead, which will reduce the number of math actions.\\n - You can optionally provide a list of strings as `context` to help the agent solve the problem. If there are multiple contexts you need to answer the question, you can provide them as a list of strings.\\n - `math` action will not see the output of the previous actions unless you provide it as `context`. You MUST provide the output of the previous actions as `context` if you need to do math on it.\\n - You MUST NEVER provide `search` type action\\'s outputs as a variable in the `problem` argument. This is because `search` returns a text blob that contains the information about the entity, not a number or value. Therefore, when you need to provide an output of `search` action, you MUST provide it as a `context` argument to `math` action. For example, 1. search(\"Barack Obama\") and then 2. math(\"age of $1\") is NEVER allowed. Use 2. math(\"age of Barack Obama\", context=[\"$1\"]) instead.\\n - When you ask a question about `context`, specify the units. For instance, \"what is xx in height?\" or \"what is xx in millions?\" instead of \"what is xx?\"' args_schema=<class 'pydantic.v1.main.mathSchema'> func=<function get_math_tool.<locals>.calculate_expression at 0x71fbd8333640>\n",
      "name='youtube_parser' description='youtube_parser(video_url: str, context: Optional[list[str]]) -> dict:\\n - Extracts metadata and comments from the provided YouTube video URL.\\n - `video_url` should be a valid YouTube video URL.\\n - You can optionally provide a list of strings as `context` to help the agent extract specific information.\\n - The returned dictionary contains video title, description, views, likes, dislikes, and comments.\\n - Minimize the number of `youtube_parser` actions as much as possible.' args_schema=<class 'pydantic.v1.main.youtube_parserSchema'> func=<function get_youtube_parser_tool.<locals>.parse_youtube_video at 0x71fbd8273760>\n"
     ]
    }
   ],
   "source": [
    "tools.append(youtube_parser_tool)\n",
    "\n",
    "for t in tools:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abdedbd-d81b-4ee9-b46f-f29439ed1350",
   "metadata": {},
   "source": [
    "# Part 2: Planner\n",
    "\n",
    "\n",
    "Largely adapted from [the original source code](https://github.com/SqueezeAILab/LLMCompiler/blob/main/src/llm_compiler/output_parser.py), the planner  accepts the input question and generates a task list to execute.\n",
    "\n",
    "If it is provided with a previous plan, it is instructed to re-plan, which is useful if, upon completion of the first batch of tasks, the agent must take more actions.\n",
    "\n",
    "The code below composes constructs the prompt template for the planner and composes it with LLM and output parser, defined in [output_parser.py](./output_parser.py). The output parser processes a task list in the following form:\n",
    "\n",
    "```plaintext\n",
    "1. tool_1(arg1=\"arg1\", arg2=3.5, ...)\n",
    "Thought: I then want to find out Y by using tool_2\n",
    "2. tool_2(arg1=\"\", arg2=\"${1}\")'\n",
    "3. join()<END_OF_PLAN>\"\n",
    "```\n",
    "\n",
    "The \"Thought\" lines are optional. The `${#}` placeholders are variables. These are used to route tool (task) outputs to other tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15dd9639-691f-4906-9012-83fd6e9ac126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Given a user query, create a plan to solve it with the utmost parallelizability. Each plan should comprise an action from the following \u001b[33;1m\u001b[1;3m{num_tools}\u001b[0m types:\n",
      "\u001b[33;1m\u001b[1;3m{tool_descriptions}\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m{num_tools}\u001b[0m. join(): Collects and combines results from prior actions.\n",
      "\n",
      " - An LLM agent is called upon invoking join() to either finalize the user query or wait until the plans are executed.\n",
      " - join should always be the last action in the plan, and will be called in two scenarios:\n",
      "   (a) if the answer can be determined by gathering the outputs from tasks to generate the final response.\n",
      "   (b) if the answer cannot be determined in the planning phase before you execute the plans. Guidelines:\n",
      " - Each action described above contains input/output types and description.\n",
      "    - You must strictly adhere to the input and output types for each action.\n",
      "    - The action descriptions contain the guidelines. You MUST strictly follow those guidelines when you use the actions.\n",
      " - Each action in the plan should strictly be one of the above types. Follow the Python conventions for each action.\n",
      " - Each action MUST have a unique ID, which is strictly increasing.\n",
      " - Inputs for actions can either be constants or outputs from preceding actions. In the latter case, use the format $id to denote the ID of the previous action whose output will be the input.\n",
      " - Always call join as the last action in the plan. Say '<END_OF_PLAN>' after you call join\n",
      " - Ensure the plan maximizes parallelizability.\n",
      " - Only use the provided action types. If a query cannot be addressed using these, invoke the join action for the next steps.\n",
      " - Never introduce new actions other than the ones provided.\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{messages}\u001b[0m\n",
      "\n",
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Remember, ONLY respond with the task list in the correct format! E.g.:\n",
      "idx. tool(arg_name=args)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    FunctionMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "\n",
    "from output_parser import LLMCompilerPlanParser, Task\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "prompt = hub.pull(\"wfh/llm-compiler\")\n",
    "print(prompt.pretty_print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45689d40-d8df-4316-a121-6ea9c87d2efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_planner(\n",
    "    llm: BaseChatModel, tools: Sequence[BaseTool], base_prompt: ChatPromptTemplate\n",
    "):\n",
    "    tool_descriptions = \"\\n\".join(\n",
    "        f\"{i+1}. {tool.description}\\n\"\n",
    "        for i, tool in enumerate(\n",
    "            tools\n",
    "        )  # +1 to offset the 0 starting index, we want it count normally from 1.\n",
    "    )\n",
    "    planner_prompt = base_prompt.partial(\n",
    "        replan=\"\",\n",
    "        num_tools=len(tools)\n",
    "        + 1,  # Add one because we're adding the join() tool at the end.\n",
    "        tool_descriptions=tool_descriptions,\n",
    "    )\n",
    "    replanner_prompt = base_prompt.partial(\n",
    "        replan=' - You are given \"Previous Plan\" which is the plan that the previous agent created along with the execution results '\n",
    "        \"(given as Observation) of each plan and a general thought (given as Thought) about the executed results.\"\n",
    "        'You MUST use these information to create the next plan under \"Current Plan\".\\n'\n",
    "        ' - When starting the Current Plan, you should start with \"Thought\" that outlines the strategy for the next plan.\\n'\n",
    "        \" - In the Current Plan, you should NEVER repeat the actions that are already executed in the Previous Plan.\\n\"\n",
    "        \" - You must continue the task index from the end of the previous one. Do not repeat task indices.\",\n",
    "        num_tools=len(tools) + 1,\n",
    "        tool_descriptions=tool_descriptions,\n",
    "    )\n",
    "\n",
    "    def should_replan(state: list):\n",
    "        # Context is passed as a system message\n",
    "        return isinstance(state[-1], SystemMessage)\n",
    "\n",
    "    def wrap_messages(state: list):\n",
    "        return {\"messages\": state}\n",
    "\n",
    "    def wrap_and_get_last_index(state: list):\n",
    "        next_task = 0\n",
    "        for message in state[::-1]:\n",
    "            if isinstance(message, FunctionMessage):\n",
    "                next_task = message.additional_kwargs[\"idx\"] + 1\n",
    "                break\n",
    "        state[-1].content = state[-1].content + f\" - Begin counting at : {next_task}\"\n",
    "        return {\"messages\": state}\n",
    "\n",
    "    return (\n",
    "        RunnableBranch(\n",
    "            (should_replan, wrap_and_get_last_index | replanner_prompt),\n",
    "            wrap_messages | planner_prompt,\n",
    "        )\n",
    "        | llm\n",
    "        | LLMCompilerPlanParser(tools=tools)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbdcb57b-5362-4b9e-88db-fb3fae443fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "# This is the primary \"agent\" in our application\n",
    "planner = create_planner(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "730490c6-6e3a-4173-82a1-9eb9d5eeff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description='tavily_search_results_json(query=\"the search query\") - a search engine.' max_results=1 {'query': 'current temperature in San Francisco'}\n",
      "---\n",
      "name='math' description='math(problem: str, context: Optional[list[str]]) -> float:\\n - Solves the provided math problem.\\n - `problem` can be either a simple math problem (e.g. \"1 + 3\") or a word problem (e.g. \"how many apples are there if there are 3 apples and 2 apples\").\\n - You cannot calculate multiple expressions in one call. For instance, `math(\\'1 + 3, 2 + 4\\')` does not work. If you need to calculate multiple expressions, you need to call them separately like `math(\\'1 + 3\\')` and then `math(\\'2 + 4\\')`\\n - Minimize the number of `math` actions as much as possible. For instance, instead of calling 2. math(\"what is the 10% of $1\") and then call 3. math(\"$1 + $2\"), you MUST call 2. math(\"what is the 110% of $1\") instead, which will reduce the number of math actions.\\n - You can optionally provide a list of strings as `context` to help the agent solve the problem. If there are multiple contexts you need to answer the question, you can provide them as a list of strings.\\n - `math` action will not see the output of the previous actions unless you provide it as `context`. You MUST provide the output of the previous actions as `context` if you need to do math on it.\\n - You MUST NEVER provide `search` type action\\'s outputs as a variable in the `problem` argument. This is because `search` returns a text blob that contains the information about the entity, not a number or value. Therefore, when you need to provide an output of `search` action, you MUST provide it as a `context` argument to `math` action. For example, 1. search(\"Barack Obama\") and then 2. math(\"age of $1\") is NEVER allowed. Use 2. math(\"age of Barack Obama\", context=[\"$1\"]) instead.\\n - When you ask a question about `context`, specify the units. For instance, \"what is xx in height?\" or \"what is xx in millions?\" instead of \"what is xx?\"' args_schema=<class 'pydantic.v1.main.mathSchema'> func=<function get_math_tool.<locals>.calculate_expression at 0x71fbd8333640> {'problem': 'current temperature in San Francisco raised to the 3rd power', 'context': ['$1']}\n",
      "---\n",
      "join ()\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "example_question = \"What's the temperature in SF raised to the 3rd power?\"\n",
    "\n",
    "for task in planner.stream([HumanMessage(content=example_question)]):\n",
    "    print(task[\"tool\"], task[\"args\"])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb446cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='youtube_parser' description='youtube_parser(video_url: str, context: Optional[list[str]]) -> dict:\\n - Extracts metadata and comments from the provided YouTube video URL.\\n - `video_url` should be a valid YouTube video URL.\\n - You can optionally provide a list of strings as `context` to help the agent extract specific information.\\n - The returned dictionary contains video title, description, views, likes, dislikes, and comments.\\n - Minimize the number of `youtube_parser` actions as much as possible.' args_schema=<class 'pydantic.v1.main.youtube_parserSchema'> func=<function get_youtube_parser_tool.<locals>.parse_youtube_video at 0x71fbd8273760> {'video_url': 'https://www.youtube.com/watch?v=dQw4w9WgXcQ', 'context': ['Krish Naik', 'datascience']}\n",
      "---\n",
      "join ()\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "example_question = \"What is the description of this video https://www.youtube.com/watch?v=dQw4w9WgXcQ by Krish naik on datascience?\"\n",
    "\n",
    "for task in planner.stream([HumanMessage(content=example_question)]):\n",
    "    print(task[\"tool\"], task[\"args\"])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a811bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description='tavily_search_results_json(query=\"the search query\") - a search engine.' max_results=1 {'query': 'latest youtube video by Krish Naik on datascience'}\n",
      "---\n",
      "name='youtube_parser' description='youtube_parser(video_url: str, context: Optional[list[str]]) -> dict:\\n - Extracts metadata and comments from the provided YouTube video URL.\\n - `video_url` should be a valid YouTube video URL.\\n - You can optionally provide a list of strings as `context` to help the agent extract specific information.\\n - The returned dictionary contains video title, description, views, likes, dislikes, and comments.\\n - Minimize the number of `youtube_parser` actions as much as possible.' args_schema=<class 'pydantic.v1.main.youtube_parserSchema'> func=<function get_youtube_parser_tool.<locals>.parse_youtube_video at 0x71fbd8273760> {'video_url': '$1'}\n",
      "---\n",
      "join ()\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "example_question = \"What is the description of the latest youtube video by Krish naik on datascience?\"\n",
    "\n",
    "for task in planner.stream([HumanMessage(content=example_question)]):\n",
    "    print(task[\"tool\"], task[\"args\"])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e795f-61ff-4553-9823-23e7624ca180",
   "metadata": {},
   "source": [
    "## 3. Task Fetching Unit\n",
    "\n",
    "This component schedules the tasks. It receives a stream of tools of the following format:\n",
    "\n",
    "```typescript\n",
    "{\n",
    "    tool: BaseTool,\n",
    "    dependencies: number[],\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "The basic idea is to begin executing tools as soon as their dependencies are met. This is done through multi-threading. We will combine the task fetching unit and executor below:\n",
    "\n",
    "![diagram](./img/diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1fbafdd-42d4-4575-8466-e5951cee71f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import Any, Union, Iterable, List, Tuple, Dict\n",
    "from typing_extensions import TypedDict\n",
    "import re\n",
    "\n",
    "from langchain_core.runnables import (\n",
    "    chain as as_runnable,\n",
    ")\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, wait\n",
    "import time\n",
    "\n",
    "\n",
    "def _get_observations(messages: List[BaseMessage]) -> Dict[int, Any]:\n",
    "    # Get all previous tool responses\n",
    "    results = {}\n",
    "    for message in messages[::-1]:\n",
    "        if isinstance(message, FunctionMessage):\n",
    "            results[int(message.additional_kwargs[\"idx\"])] = message.content\n",
    "    return results\n",
    "\n",
    "\n",
    "class SchedulerInput(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    tasks: Iterable[Task]\n",
    "\n",
    "\n",
    "def _execute_task(task, observations, config):\n",
    "    tool_to_use = task[\"tool\"]\n",
    "    if isinstance(tool_to_use, str):\n",
    "        return tool_to_use\n",
    "    args = task[\"args\"]\n",
    "    try:\n",
    "        if isinstance(args, str):\n",
    "            resolved_args = _resolve_arg(args, observations)\n",
    "        elif isinstance(args, dict):\n",
    "            resolved_args = {\n",
    "                key: _resolve_arg(val, observations) for key, val in args.items()\n",
    "            }\n",
    "        else:\n",
    "            # This will likely fail\n",
    "            resolved_args = args\n",
    "    except Exception as e:\n",
    "        return (\n",
    "            f\"ERROR(Failed to call {tool_to_use.name} with args {args}.)\"\n",
    "            f\" Args could not be resolved. Error: {repr(e)}\"\n",
    "        )\n",
    "    try:\n",
    "        return tool_to_use.invoke(resolved_args, config)\n",
    "    except Exception as e:\n",
    "        return (\n",
    "            f\"ERROR(Failed to call {tool_to_use.name} with args {args}.\"\n",
    "            + f\" Args resolved to {resolved_args}. Error: {repr(e)})\"\n",
    "        )\n",
    "\n",
    "\n",
    "def _resolve_arg(arg: Union[str, Any], observations: Dict[int, Any]):\n",
    "    # $1 or ${1} -> 1\n",
    "    ID_PATTERN = r\"\\$\\{?(\\d+)\\}?\"\n",
    "\n",
    "    def replace_match(match):\n",
    "        # If the string is ${123}, match.group(0) is ${123}, and match.group(1) is 123.\n",
    "\n",
    "        # Return the match group, in this case the index, from the string. This is the index\n",
    "        # number we get back.\n",
    "        idx = int(match.group(1))\n",
    "        return str(observations.get(idx, match.group(0)))\n",
    "\n",
    "    # For dependencies on other tasks\n",
    "    if isinstance(arg, str):\n",
    "        return re.sub(ID_PATTERN, replace_match, arg)\n",
    "    elif isinstance(arg, list):\n",
    "        return [_resolve_arg(a, observations) for a in arg]\n",
    "    else:\n",
    "        return str(arg)\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "def schedule_task(task_inputs, config):\n",
    "    task: Task = task_inputs[\"task\"]\n",
    "    observations: Dict[int, Any] = task_inputs[\"observations\"]\n",
    "    try:\n",
    "        observation = _execute_task(task, observations, config)\n",
    "    except Exception:\n",
    "        import traceback\n",
    "\n",
    "        observation = traceback.format_exception()  # repr(e) +\n",
    "    observations[task[\"idx\"]] = observation\n",
    "\n",
    "\n",
    "def schedule_pending_task(\n",
    "    task: Task, observations: Dict[int, Any], retry_after: float = 0.2\n",
    "):\n",
    "    while True:\n",
    "        deps = task[\"dependencies\"]\n",
    "        if deps and (any([dep not in observations for dep in deps])):\n",
    "            # Dependencies not yet satisfied\n",
    "            time.sleep(retry_after)\n",
    "            continue\n",
    "        schedule_task.invoke({\"task\": task, \"observations\": observations})\n",
    "        break\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "def schedule_tasks(scheduler_input: SchedulerInput) -> List[FunctionMessage]:\n",
    "    \"\"\"Group the tasks into a DAG schedule.\"\"\"\n",
    "    # For streaming, we are making a few simplifying assumption:\n",
    "    # 1. The LLM does not create cyclic dependencies\n",
    "    # 2. That the LLM will not generate tasks with future deps\n",
    "    # If this ceases to be a good assumption, you can either\n",
    "    # adjust to do a proper topological sort (not-stream)\n",
    "    # or use a more complicated data structure\n",
    "    tasks = scheduler_input[\"tasks\"]\n",
    "    args_for_tasks = {}\n",
    "    messages = scheduler_input[\"messages\"]\n",
    "    # If we are re-planning, we may have calls that depend on previous\n",
    "    # plans. Start with those.\n",
    "    observations = _get_observations(messages)\n",
    "    task_names = {}\n",
    "    originals = set(observations)\n",
    "    # ^^ We assume each task inserts a different key above to\n",
    "    # avoid race conditions...\n",
    "    futures = []\n",
    "    retry_after = 0.25  # Retry every quarter second\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for task in tasks:\n",
    "            deps = task[\"dependencies\"]\n",
    "            task_names[task[\"idx\"]] = (\n",
    "                task[\"tool\"] if isinstance(task[\"tool\"], str) else task[\"tool\"].name\n",
    "            )\n",
    "            args_for_tasks[task[\"idx\"]] = task[\"args\"]\n",
    "            if (\n",
    "                # Depends on other tasks\n",
    "                deps\n",
    "                and (any([dep not in observations for dep in deps]))\n",
    "            ):\n",
    "                futures.append(\n",
    "                    executor.submit(\n",
    "                        schedule_pending_task, task, observations, retry_after\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                # No deps or all deps satisfied\n",
    "                # can schedule now\n",
    "                schedule_task.invoke(dict(task=task, observations=observations))\n",
    "                # futures.append(executor.submit(schedule_task.invoke dict(task=task, observations=observations)))\n",
    "\n",
    "        # All tasks have been submitted or enqueued\n",
    "        # Wait for them to complete\n",
    "        wait(futures)\n",
    "    # Convert observations to new tool messages to add to the state\n",
    "    new_observations = {\n",
    "        k: (task_names[k], args_for_tasks[k], observations[k])\n",
    "        for k in sorted(observations.keys() - originals)\n",
    "    }\n",
    "    tool_messages = [\n",
    "        FunctionMessage(\n",
    "            name=name, content=str(obs), additional_kwargs={\"idx\": k, \"args\": task_args}\n",
    "        )\n",
    "        for k, (name, task_args, obs) in new_observations.items()\n",
    "    ]\n",
    "    return tool_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "052f6b16-103a-40e9-94dd-8fcc37e77ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "def plan_and_schedule(messages: List[BaseMessage], config):\n",
    "    tasks = planner.stream(messages, config)\n",
    "    # Begin executing the planner immediately\n",
    "    try:\n",
    "        tasks = itertools.chain([next(tasks)], tasks)\n",
    "    except StopIteration:\n",
    "        # Handle the case where tasks is empty.\n",
    "        tasks = iter([])\n",
    "    scheduled_tasks = schedule_tasks.invoke(\n",
    "        {\n",
    "            \"messages\": messages,\n",
    "            \"tasks\": tasks,\n",
    "        },\n",
    "        config,\n",
    "    )\n",
    "    return scheduled_tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efa15ae-817a-48c6-86ed-16bc112fedc5",
   "metadata": {},
   "source": [
    "#### Example Plan\n",
    "\n",
    "We still haven't introduced any cycles in our computation graph, so this is all easily expressed in LCEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87e81851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the description of the latest youtube video by Krish naik on datascience?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55142257-2674-4a47-988e-0d2810917329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA MODEL = video_url='https://www.youtube.com/watch?v=JxgmHe2NyeY' context=None\n"
     ]
    }
   ],
   "source": [
    "tool_messages = plan_and_schedule.invoke([HumanMessage(content=example_question)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a98e0525-2fcf-4fa1-baf6-79858bb8a6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionMessage(content=\"[{'url': 'https://www.youtube.com/watch?v=JxgmHe2NyeY', 'content': 'All the materials are available in the below linkhttps://github.com/krishnaik06/The-Grand-Complete-Data-Science-Materials/tree/mainVisit https://krishnaik.in...'}]\", additional_kwargs={'idx': 1, 'args': {'query': 'latest youtube video by Krish Naik on datascience'}}, name='tavily_search_results_json'),\n",
       " FunctionMessage(content=\"{'url': 'https://www.youtube.com/watch?v=JxgmHe2NyeY', 'title': 'Sample Title', 'description': 'Sample description of the video.', 'views': '12345', 'likes': '678', 'dislikes': '90', 'comments': [{'author': 'User1', 'text': 'Sample comment 1'}, {'author': 'User2', 'text': 'Sample comment 2'}]}\", additional_kwargs={'idx': 2, 'args': {'video_url': 'URL from $1'}}, name='youtube_parser'),\n",
       " FunctionMessage(content='join', additional_kwargs={'idx': 3, 'args': ()}, name='join')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563d5311-55f0-4ca1-afbd-01fd970cf3e3",
   "metadata": {},
   "source": [
    "## 4. \"Joiner\" \n",
    "\n",
    "So now we have the planning and initial execution done. We need a component to process these outputs and either:\n",
    "\n",
    "1. Respond with the correct answer.\n",
    "2. Loop with a new plan.\n",
    "\n",
    "The paper refers to this as the \"joiner\". It's another LLM call. We are using function calling to improve parsing reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "942dab42-ad42-4ba2-90d5-49edbe4fae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.chains.openai_functions import create_structured_output_runnable\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "\n",
    "class FinalResponse(BaseModel):\n",
    "    \"\"\"The final response/answer.\"\"\"\n",
    "\n",
    "    response: str\n",
    "\n",
    "\n",
    "class Replan(BaseModel):\n",
    "    feedback: str = Field(\n",
    "        description=\"Analysis of the previous attempts and recommendations on what needs to be fixed.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class JoinOutputs(BaseModel):\n",
    "    \"\"\"Decide whether to replan or whether you can return the final response.\"\"\"\n",
    "\n",
    "    thought: str = Field(\n",
    "        description=\"The chain of thought reasoning for the selected action\"\n",
    "    )\n",
    "    action: Union[FinalResponse, Replan]\n",
    "\n",
    "\n",
    "joiner_prompt = hub.pull(\"wfh/llm-compiler-joiner\").partial(\n",
    "    examples=\"\"\n",
    ")  # You can optionally add examples\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "runnable = create_structured_output_runnable(JoinOutputs, llm, joiner_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb50c4cd-947c-4a5d-a9f7-f0d92a10600f",
   "metadata": {},
   "source": [
    "We will select only the most recent messages in the state, and format the output to be more useful for\n",
    "the planner, should the agent need to loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "951a33cf-2a05-4a33-899a-0ab1d97122fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_joiner_output(decision: JoinOutputs) -> List[BaseMessage]:\n",
    "    response = [AIMessage(content=f\"Thought: {decision.thought}\")]\n",
    "    if isinstance(decision.action, Replan):\n",
    "        return response + [\n",
    "            SystemMessage(\n",
    "                content=f\"Context from last attempt: {decision.action.feedback}\"\n",
    "            )\n",
    "        ]\n",
    "    else:\n",
    "        return response + [AIMessage(content=decision.action.response)]\n",
    "\n",
    "\n",
    "def select_recent_messages(messages: list) -> dict:\n",
    "    selected = []\n",
    "    for msg in messages[::-1]:\n",
    "        selected.append(msg)\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            break\n",
    "    return {\"messages\": selected[::-1]}\n",
    "\n",
    "\n",
    "joiner = select_recent_messages | runnable | _parse_joiner_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e49d4b1-8266-4520-a566-1448b1c31c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_messages = [HumanMessage(content=example_question)] + tool_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31854dfd-b82f-4c24-9b58-6bae66777909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Thought: The description of the latest YouTube video by Krish Naik includes a link to materials on GitHub and a mention of his website.'),\n",
       " AIMessage(content='The description of the latest YouTube video by Krish Naik on data science includes a link to materials on GitHub and a mention of his website. You can find all the materials at the provided GitHub link: https://github.com/krishnaik06/The-Grand-Complete-Data-Science-Materials/tree/main and visit https://krishnaik.in for more information.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joiner.invoke(input_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b099e5ee-2c23-47d9-9387-0f64e02627d3",
   "metadata": {},
   "source": [
    "## 5. Compose using LangGraph\n",
    "\n",
    "We'll define the agent as a stateful graph, with the main nodes being:\n",
    "\n",
    "1. Plan and execute (the DAG from the first step above)\n",
    "2. Join: determine if we should finish or replan\n",
    "3. Recontextualize: update the graph state based on the output from the joiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "768b5f11-e3d2-47be-8143-a7dcd8765243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessageGraph, END\n",
    "from langchain_core.agents import AgentFinish\n",
    "from typing import Dict\n",
    "\n",
    "graph_builder = MessageGraph()\n",
    "\n",
    "# 1.  Define vertices\n",
    "# We defined plan_and_schedule above already\n",
    "# Assign each node to a state variable to update\n",
    "graph_builder.add_node(\"plan_and_schedule\", plan_and_schedule)\n",
    "graph_builder.add_node(\"join\", joiner)\n",
    "\n",
    "\n",
    "## Define edges\n",
    "graph_builder.add_edge(\"plan_and_schedule\", \"join\")\n",
    "\n",
    "### This condition determines looping logic\n",
    "\n",
    "\n",
    "def should_continue(state: List[BaseMessage]):\n",
    "    print(\"> should_continue  STATE =\", state)\n",
    "    if isinstance(state[-1], AIMessage) or \"END\" in state[-1].content:\n",
    "        return END\n",
    "    return \"plan_and_schedule\"\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"join\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "graph_builder.set_entry_point(\"plan_and_schedule\")\n",
    "chain = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8c9849-8531-463d-a0ef-dcc3d9888b2d",
   "metadata": {},
   "source": [
    "#### Simple question\n",
    "\n",
    "Let's ask a simple question of the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bc4584a-e31c-4065-805e-76a6db30676a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': [FunctionMessage(content='[{\\'url\\': \\'https://www.statista.com/statistics/188087/gdp-of-the-us-federal-state-of-new-york-since-1997/\\', \\'content\\': \\'Industry Overview\\\\nDigital & Trend reports\\\\nOverview and forecasts on trending topics\\\\nIndustry & Market reports\\\\nIndustry and market insights and forecasts\\\\nCompanies & Products reports\\\\nKey figures and rankings about companies and products\\\\nConsumer & Brand reports\\\\nConsumer and brand insights and preferences in various industries\\\\nPolitics & Society reports\\\\nDetailed information about political and social topics\\\\nCountry & Region reports\\\\nAll key figures about countries and regions\\\\nMarket forecast and expert KPIs for 1000+ markets in 190+ countries & territories\\\\nInsights on consumer attitudes and behavior worldwide\\\\nBusiness information on 100m+ public and private companies\\\\nExplore Company Insights\\\\nDetailed information for 39,000+ online stores and marketplaces\\\\nDirectly accessible data for 170 industries from 150+ countries\\\\nand over 1\\\\xa0Mio. facts.\\\\n Transforming data into design:\\\\nStatista Content & Design\\\\nStrategy and business building for the data-driven economy:\\\\nU.S. real GDP of New York 2000-2022\\\\nReal gross domestic product of New York in the United States\\\\nfrom 2000 to 2022\\\\n(in billion U.S. dollars)\\\\nAdditional Information\\\\nShow sources information\\\\nShow publisher information\\\\nUse Ask Statista Research Service\\\\nMarch 2023\\\\nUnited States\\\\n2000 to 2022\\\\nData presented here is in 2012 chained U.S. dollars.\\\\n Statistics on\\\\n\"\\\\nNew York\\\\n\"\\\\nOther statistics that may interest you New York\\\\nPopulation\\\\nEconomy\\\\nEmployment & Earnings\\\\nState & Local Government\\\\nNew York City\\\\nFurther related statistics\\\\nFurther Content: You might find this interesting as well\\\\nStatistics\\\\nTopics Other statistics on the topic\\\\nEconomy\\\\nU.S. real gross domestic product 2022, by state\\\\nPolitics & Government\\\\nU.S. state and local government outstanding debt 2021, by state\\\\nDemographics\\\\nResident population in New York 1960-2022\\\\nEconomy\\\\nU.S. New York metro area GDP 2001-2022\\\\nYou only have access to basic statistics.\\\\n Customized Research & Analysis projects:\\\\nGet quick analyses with our professional research service\\\\nThe best of the best: the portal for top lists & rankings:\\\\n\\'}]', additional_kwargs={'idx': 1, 'args': {'query': 'GDP of New York'}}, name='tavily_search_results_json', id='7d1f420b-b4bc-4848-8d80-cf564928f0a5'), FunctionMessage(content='join', additional_kwargs={'idx': 2, 'args': ()}, name='join', id='fd981f92-a727-4f43-a002-7a224c7a95df')]}\n",
      "---\n",
      "> should_continue  STATE = [HumanMessage(content=\"What's the GDP of New York?\", id='0cda0c19-dad3-4151-be05-eea1a876a543'), FunctionMessage(content='[{\\'url\\': \\'https://www.statista.com/statistics/188087/gdp-of-the-us-federal-state-of-new-york-since-1997/\\', \\'content\\': \\'Industry Overview\\\\nDigital & Trend reports\\\\nOverview and forecasts on trending topics\\\\nIndustry & Market reports\\\\nIndustry and market insights and forecasts\\\\nCompanies & Products reports\\\\nKey figures and rankings about companies and products\\\\nConsumer & Brand reports\\\\nConsumer and brand insights and preferences in various industries\\\\nPolitics & Society reports\\\\nDetailed information about political and social topics\\\\nCountry & Region reports\\\\nAll key figures about countries and regions\\\\nMarket forecast and expert KPIs for 1000+ markets in 190+ countries & territories\\\\nInsights on consumer attitudes and behavior worldwide\\\\nBusiness information on 100m+ public and private companies\\\\nExplore Company Insights\\\\nDetailed information for 39,000+ online stores and marketplaces\\\\nDirectly accessible data for 170 industries from 150+ countries\\\\nand over 1\\\\xa0Mio. facts.\\\\n Transforming data into design:\\\\nStatista Content & Design\\\\nStrategy and business building for the data-driven economy:\\\\nU.S. real GDP of New York 2000-2022\\\\nReal gross domestic product of New York in the United States\\\\nfrom 2000 to 2022\\\\n(in billion U.S. dollars)\\\\nAdditional Information\\\\nShow sources information\\\\nShow publisher information\\\\nUse Ask Statista Research Service\\\\nMarch 2023\\\\nUnited States\\\\n2000 to 2022\\\\nData presented here is in 2012 chained U.S. dollars.\\\\n Statistics on\\\\n\"\\\\nNew York\\\\n\"\\\\nOther statistics that may interest you New York\\\\nPopulation\\\\nEconomy\\\\nEmployment & Earnings\\\\nState & Local Government\\\\nNew York City\\\\nFurther related statistics\\\\nFurther Content: You might find this interesting as well\\\\nStatistics\\\\nTopics Other statistics on the topic\\\\nEconomy\\\\nU.S. real gross domestic product 2022, by state\\\\nPolitics & Government\\\\nU.S. state and local government outstanding debt 2021, by state\\\\nDemographics\\\\nResident population in New York 1960-2022\\\\nEconomy\\\\nU.S. New York metro area GDP 2001-2022\\\\nYou only have access to basic statistics.\\\\n Customized Research & Analysis projects:\\\\nGet quick analyses with our professional research service\\\\nThe best of the best: the portal for top lists & rankings:\\\\n\\'}]', additional_kwargs={'idx': 1, 'args': {'query': 'GDP of New York'}}, name='tavily_search_results_json', id='7d1f420b-b4bc-4848-8d80-cf564928f0a5'), FunctionMessage(content='join', additional_kwargs={'idx': 2, 'args': ()}, name='join', id='fd981f92-a727-4f43-a002-7a224c7a95df'), AIMessage(content=\"Thought: The information about the GDP of New York is not explicitly stated in the provided search result. It only mentions the availability of data from 2000 to 2022 in billion U.S. dollars but doesn't give a specific figure for the current GDP.\", id='0942a57c-246c-408b-b8ac-6de8f66cc7c2'), SystemMessage(content='Context from last attempt: The search results do not provide a specific GDP figure for New York. We need to find a specific source or data point that states the current GDP.', id='c1cc7d86-a933-4d71-beca-6fa2c3e5fc5f')]\n",
      "{'join': [AIMessage(content=\"Thought: The information about the GDP of New York is not explicitly stated in the provided search result. It only mentions the availability of data from 2000 to 2022 in billion U.S. dollars but doesn't give a specific figure for the current GDP.\", id='0942a57c-246c-408b-b8ac-6de8f66cc7c2'), SystemMessage(content='Context from last attempt: The search results do not provide a specific GDP figure for New York. We need to find a specific source or data point that states the current GDP.', id='c1cc7d86-a933-4d71-beca-6fa2c3e5fc5f')]}\n",
      "---\n",
      "{'plan_and_schedule': [FunctionMessage(content='[{\\'url\\': \\'https://www.bea.gov/news/2024/gross-domestic-product-fourth-quarter-and-year-2023-advance-estimate\\', \\'content\\': \\'Real gross domestic product (GDP) increased at an annual rate of 3.3 percent in the fourth quarter of 2023 (table 1), according to the \"advance\" estimate released by the Bureau of Economic Analysis. In the third quarter, real GDP increased 4.9 percent. The GDP estimate released today is based on source data that are incomplete or subject to further revision by the source agency (refer to ...\\'}]', additional_kwargs={'idx': 3, 'args': {'query': 'current GDP of New York 2023'}}, name='tavily_search_results_json', id='994d4232-e0b2-435c-ba40-ae2d8ba239f7')]}\n",
      "---\n",
      "> should_continue  STATE = [HumanMessage(content=\"What's the GDP of New York?\", id='0cda0c19-dad3-4151-be05-eea1a876a543'), FunctionMessage(content='[{\\'url\\': \\'https://www.statista.com/statistics/188087/gdp-of-the-us-federal-state-of-new-york-since-1997/\\', \\'content\\': \\'Industry Overview\\\\nDigital & Trend reports\\\\nOverview and forecasts on trending topics\\\\nIndustry & Market reports\\\\nIndustry and market insights and forecasts\\\\nCompanies & Products reports\\\\nKey figures and rankings about companies and products\\\\nConsumer & Brand reports\\\\nConsumer and brand insights and preferences in various industries\\\\nPolitics & Society reports\\\\nDetailed information about political and social topics\\\\nCountry & Region reports\\\\nAll key figures about countries and regions\\\\nMarket forecast and expert KPIs for 1000+ markets in 190+ countries & territories\\\\nInsights on consumer attitudes and behavior worldwide\\\\nBusiness information on 100m+ public and private companies\\\\nExplore Company Insights\\\\nDetailed information for 39,000+ online stores and marketplaces\\\\nDirectly accessible data for 170 industries from 150+ countries\\\\nand over 1\\\\xa0Mio. facts.\\\\n Transforming data into design:\\\\nStatista Content & Design\\\\nStrategy and business building for the data-driven economy:\\\\nU.S. real GDP of New York 2000-2022\\\\nReal gross domestic product of New York in the United States\\\\nfrom 2000 to 2022\\\\n(in billion U.S. dollars)\\\\nAdditional Information\\\\nShow sources information\\\\nShow publisher information\\\\nUse Ask Statista Research Service\\\\nMarch 2023\\\\nUnited States\\\\n2000 to 2022\\\\nData presented here is in 2012 chained U.S. dollars.\\\\n Statistics on\\\\n\"\\\\nNew York\\\\n\"\\\\nOther statistics that may interest you New York\\\\nPopulation\\\\nEconomy\\\\nEmployment & Earnings\\\\nState & Local Government\\\\nNew York City\\\\nFurther related statistics\\\\nFurther Content: You might find this interesting as well\\\\nStatistics\\\\nTopics Other statistics on the topic\\\\nEconomy\\\\nU.S. real gross domestic product 2022, by state\\\\nPolitics & Government\\\\nU.S. state and local government outstanding debt 2021, by state\\\\nDemographics\\\\nResident population in New York 1960-2022\\\\nEconomy\\\\nU.S. New York metro area GDP 2001-2022\\\\nYou only have access to basic statistics.\\\\n Customized Research & Analysis projects:\\\\nGet quick analyses with our professional research service\\\\nThe best of the best: the portal for top lists & rankings:\\\\n\\'}]', additional_kwargs={'idx': 1, 'args': {'query': 'GDP of New York'}}, name='tavily_search_results_json', id='7d1f420b-b4bc-4848-8d80-cf564928f0a5'), FunctionMessage(content='join', additional_kwargs={'idx': 2, 'args': ()}, name='join', id='fd981f92-a727-4f43-a002-7a224c7a95df'), AIMessage(content=\"Thought: The information about the GDP of New York is not explicitly stated in the provided search result. It only mentions the availability of data from 2000 to 2022 in billion U.S. dollars but doesn't give a specific figure for the current GDP.\", id='0942a57c-246c-408b-b8ac-6de8f66cc7c2'), SystemMessage(content='Context from last attempt: The search results do not provide a specific GDP figure for New York. We need to find a specific source or data point that states the current GDP. - Begin counting at : 3', id='c1cc7d86-a933-4d71-beca-6fa2c3e5fc5f'), FunctionMessage(content='[{\\'url\\': \\'https://www.bea.gov/news/2024/gross-domestic-product-fourth-quarter-and-year-2023-advance-estimate\\', \\'content\\': \\'Real gross domestic product (GDP) increased at an annual rate of 3.3 percent in the fourth quarter of 2023 (table 1), according to the \"advance\" estimate released by the Bureau of Economic Analysis. In the third quarter, real GDP increased 4.9 percent. The GDP estimate released today is based on source data that are incomplete or subject to further revision by the source agency (refer to ...\\'}]', additional_kwargs={'idx': 3, 'args': {'query': 'current GDP of New York 2023'}}, name='tavily_search_results_json', id='994d4232-e0b2-435c-ba40-ae2d8ba239f7'), AIMessage(content='Thought: The search results do not provide a specific GDP figure for New York. We need to find a specific source or data point that states the current GDP.', id='d1be8500-64cc-475b-9e88-46f45c0a2ddc'), SystemMessage(content='Context from last attempt: The current search results do not provide the specific GDP figure for New York. We need to search for a specific source or data point that states the current GDP of New York.', id='02aaa0a8-4404-4566-bfde-78a441596caf')]\n",
      "{'join': [AIMessage(content='Thought: The search results do not provide a specific GDP figure for New York. We need to find a specific source or data point that states the current GDP.', id='d1be8500-64cc-475b-9e88-46f45c0a2ddc'), SystemMessage(content='Context from last attempt: The current search results do not provide the specific GDP figure for New York. We need to search for a specific source or data point that states the current GDP of New York.', id='02aaa0a8-4404-4566-bfde-78a441596caf')]}\n",
      "---\n",
      "{'plan_and_schedule': [FunctionMessage(content='[{\\'url\\': \\'https://www.statista.com/statistics/188087/gdp-of-the-us-federal-state-of-new-york-since-1997/\\', \\'content\\': \\'Industry Overview\\\\nDigital & Trend reports\\\\nOverview and forecasts on trending topics\\\\nIndustry & Market reports\\\\nIndustry and market insights and forecasts\\\\nCompanies & Products reports\\\\nKey figures and rankings about companies and products\\\\nConsumer & Brand reports\\\\nConsumer and brand insights and preferences in various industries\\\\nPolitics & Society reports\\\\nDetailed information about political and social topics\\\\nCountry & Region reports\\\\nAll key figures about countries and regions\\\\nMarket forecast and expert KPIs for 1000+ markets in 190+ countries & territories\\\\nInsights on consumer attitudes and behavior worldwide\\\\nBusiness information on 100m+ public and private companies\\\\nExplore Company Insights\\\\nDetailed information for 39,000+ online stores and marketplaces\\\\nDirectly accessible data for 170 industries from 150+ countries\\\\nand over 1\\\\xa0Mio. facts.\\\\n Transforming data into design:\\\\nStatista Content & Design\\\\nStrategy and business building for the data-driven economy:\\\\nU.S. real GDP of New York 2000-2022\\\\nReal gross domestic product of New York in the United States\\\\nfrom 2000 to 2022\\\\n(in billion U.S. dollars)\\\\nAdditional Information\\\\nShow sources information\\\\nShow publisher information\\\\nUse Ask Statista Research Service\\\\nMarch 2023\\\\nUnited States\\\\n2000 to 2022\\\\nData presented here is in 2012 chained U.S. dollars.\\\\n Statistics on\\\\n\"\\\\nNew York\\\\n\"\\\\nOther statistics that may interest you New York\\\\nPopulation\\\\nEconomy\\\\nEmployment & Earnings\\\\nState & Local Government\\\\nNew York City\\\\nFurther related statistics\\\\nFurther Content: You might find this interesting as well\\\\nStatistics\\\\nTopics Other statistics on the topic\\\\nEconomy\\\\nU.S. real gross domestic product 2022, by state\\\\nPolitics & Government\\\\nU.S. state and local government outstanding debt 2021, by state\\\\nDemographics\\\\nResident population in New York 1960-2022\\\\nEconomy\\\\nU.S. New York metro area GDP 2001-2022\\\\nYou only have access to basic statistics.\\\\n Customized Research & Analysis projects:\\\\nGet quick analyses with our professional research service\\\\nThe best of the best: the portal for top lists & rankings:\\\\n\\'}]', additional_kwargs={'idx': 4, 'args': {'query': 'current GDP of New York 2023'}}, name='tavily_search_results_json', id='a346307c-d149-4bab-a39b-a5e2ced2092b')]}\n",
      "---\n",
      "> should_continue  STATE = [HumanMessage(content=\"What's the GDP of New York?\", id='0cda0c19-dad3-4151-be05-eea1a876a543'), FunctionMessage(content='[{\\'url\\': \\'https://www.statista.com/statistics/188087/gdp-of-the-us-federal-state-of-new-york-since-1997/\\', \\'content\\': \\'Industry Overview\\\\nDigital & Trend reports\\\\nOverview and forecasts on trending topics\\\\nIndustry & Market reports\\\\nIndustry and market insights and forecasts\\\\nCompanies & Products reports\\\\nKey figures and rankings about companies and products\\\\nConsumer & Brand reports\\\\nConsumer and brand insights and preferences in various industries\\\\nPolitics & Society reports\\\\nDetailed information about political and social topics\\\\nCountry & Region reports\\\\nAll key figures about countries and regions\\\\nMarket forecast and expert KPIs for 1000+ markets in 190+ countries & territories\\\\nInsights on consumer attitudes and behavior worldwide\\\\nBusiness information on 100m+ public and private companies\\\\nExplore Company Insights\\\\nDetailed information for 39,000+ online stores and marketplaces\\\\nDirectly accessible data for 170 industries from 150+ countries\\\\nand over 1\\\\xa0Mio. facts.\\\\n Transforming data into design:\\\\nStatista Content & Design\\\\nStrategy and business building for the data-driven economy:\\\\nU.S. real GDP of New York 2000-2022\\\\nReal gross domestic product of New York in the United States\\\\nfrom 2000 to 2022\\\\n(in billion U.S. dollars)\\\\nAdditional Information\\\\nShow sources information\\\\nShow publisher information\\\\nUse Ask Statista Research Service\\\\nMarch 2023\\\\nUnited States\\\\n2000 to 2022\\\\nData presented here is in 2012 chained U.S. dollars.\\\\n Statistics on\\\\n\"\\\\nNew York\\\\n\"\\\\nOther statistics that may interest you New York\\\\nPopulation\\\\nEconomy\\\\nEmployment & Earnings\\\\nState & Local Government\\\\nNew York City\\\\nFurther related statistics\\\\nFurther Content: You might find this interesting as well\\\\nStatistics\\\\nTopics Other statistics on the topic\\\\nEconomy\\\\nU.S. real gross domestic product 2022, by state\\\\nPolitics & Government\\\\nU.S. state and local government outstanding debt 2021, by state\\\\nDemographics\\\\nResident population in New York 1960-2022\\\\nEconomy\\\\nU.S. New York metro area GDP 2001-2022\\\\nYou only have access to basic statistics.\\\\n Customized Research & Analysis projects:\\\\nGet quick analyses with our professional research service\\\\nThe best of the best: the portal for top lists & rankings:\\\\n\\'}]', additional_kwargs={'idx': 1, 'args': {'query': 'GDP of New York'}}, name='tavily_search_results_json', id='7d1f420b-b4bc-4848-8d80-cf564928f0a5'), FunctionMessage(content='join', additional_kwargs={'idx': 2, 'args': ()}, name='join', id='fd981f92-a727-4f43-a002-7a224c7a95df'), AIMessage(content=\"Thought: The information about the GDP of New York is not explicitly stated in the provided search result. It only mentions the availability of data from 2000 to 2022 in billion U.S. dollars but doesn't give a specific figure for the current GDP.\", id='0942a57c-246c-408b-b8ac-6de8f66cc7c2'), SystemMessage(content='Context from last attempt: The search results do not provide a specific GDP figure for New York. We need to find a specific source or data point that states the current GDP. - Begin counting at : 3', id='c1cc7d86-a933-4d71-beca-6fa2c3e5fc5f'), FunctionMessage(content='[{\\'url\\': \\'https://www.bea.gov/news/2024/gross-domestic-product-fourth-quarter-and-year-2023-advance-estimate\\', \\'content\\': \\'Real gross domestic product (GDP) increased at an annual rate of 3.3 percent in the fourth quarter of 2023 (table 1), according to the \"advance\" estimate released by the Bureau of Economic Analysis. In the third quarter, real GDP increased 4.9 percent. The GDP estimate released today is based on source data that are incomplete or subject to further revision by the source agency (refer to ...\\'}]', additional_kwargs={'idx': 3, 'args': {'query': 'current GDP of New York 2023'}}, name='tavily_search_results_json', id='994d4232-e0b2-435c-ba40-ae2d8ba239f7'), AIMessage(content='Thought: The search results do not provide a specific GDP figure for New York. We need to find a specific source or data point that states the current GDP.', id='d1be8500-64cc-475b-9e88-46f45c0a2ddc'), SystemMessage(content='Context from last attempt: The current search results do not provide the specific GDP figure for New York. We need to search for a specific source or data point that states the current GDP of New York. - Begin counting at : 4', id='02aaa0a8-4404-4566-bfde-78a441596caf'), FunctionMessage(content='[{\\'url\\': \\'https://www.statista.com/statistics/188087/gdp-of-the-us-federal-state-of-new-york-since-1997/\\', \\'content\\': \\'Industry Overview\\\\nDigital & Trend reports\\\\nOverview and forecasts on trending topics\\\\nIndustry & Market reports\\\\nIndustry and market insights and forecasts\\\\nCompanies & Products reports\\\\nKey figures and rankings about companies and products\\\\nConsumer & Brand reports\\\\nConsumer and brand insights and preferences in various industries\\\\nPolitics & Society reports\\\\nDetailed information about political and social topics\\\\nCountry & Region reports\\\\nAll key figures about countries and regions\\\\nMarket forecast and expert KPIs for 1000+ markets in 190+ countries & territories\\\\nInsights on consumer attitudes and behavior worldwide\\\\nBusiness information on 100m+ public and private companies\\\\nExplore Company Insights\\\\nDetailed information for 39,000+ online stores and marketplaces\\\\nDirectly accessible data for 170 industries from 150+ countries\\\\nand over 1\\\\xa0Mio. facts.\\\\n Transforming data into design:\\\\nStatista Content & Design\\\\nStrategy and business building for the data-driven economy:\\\\nU.S. real GDP of New York 2000-2022\\\\nReal gross domestic product of New York in the United States\\\\nfrom 2000 to 2022\\\\n(in billion U.S. dollars)\\\\nAdditional Information\\\\nShow sources information\\\\nShow publisher information\\\\nUse Ask Statista Research Service\\\\nMarch 2023\\\\nUnited States\\\\n2000 to 2022\\\\nData presented here is in 2012 chained U.S. dollars.\\\\n Statistics on\\\\n\"\\\\nNew York\\\\n\"\\\\nOther statistics that may interest you New York\\\\nPopulation\\\\nEconomy\\\\nEmployment & Earnings\\\\nState & Local Government\\\\nNew York City\\\\nFurther related statistics\\\\nFurther Content: You might find this interesting as well\\\\nStatistics\\\\nTopics Other statistics on the topic\\\\nEconomy\\\\nU.S. real gross domestic product 2022, by state\\\\nPolitics & Government\\\\nU.S. state and local government outstanding debt 2021, by state\\\\nDemographics\\\\nResident population in New York 1960-2022\\\\nEconomy\\\\nU.S. New York metro area GDP 2001-2022\\\\nYou only have access to basic statistics.\\\\n Customized Research & Analysis projects:\\\\nGet quick analyses with our professional research service\\\\nThe best of the best: the portal for top lists & rankings:\\\\n\\'}]', additional_kwargs={'idx': 4, 'args': {'query': 'current GDP of New York 2023'}}, name='tavily_search_results_json', id='a346307c-d149-4bab-a39b-a5e2ced2092b'), AIMessage(content='Thought: The search results still do not provide a specific GDP figure for New York. Given multiple attempts, it is clear we do not have the exact information needed.', id='8d7382a9-aa0c-497b-8611-3b118987d63f'), AIMessage(content=\"I couldn't find the exact current GDP figure for New York. However, you can find detailed GDP data for New York from 2000 to 2022 on platforms like Statista or the Bureau of Economic Analysis (BEA) websites.\", id='6471db7a-440a-4710-84a4-91466ab2b890')]\n",
      "{'join': [AIMessage(content='Thought: The search results still do not provide a specific GDP figure for New York. Given multiple attempts, it is clear we do not have the exact information needed.', id='8d7382a9-aa0c-497b-8611-3b118987d63f'), AIMessage(content=\"I couldn't find the exact current GDP figure for New York. However, you can find detailed GDP data for New York from 2000 to 2022 on platforms like Statista or the Bureau of Economic Analysis (BEA) websites.\", id='6471db7a-440a-4710-84a4-91466ab2b890')]}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for step in chain.stream([HumanMessage(content=\"What's the GDP of New York?\")]):\n",
    "    print(step)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b96efd08-5314-44f0-a694-3073b638adad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': []}\n"
     ]
    }
   ],
   "source": [
    "# Final answer\n",
    "print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c65ef5-b4b2-4ab2-8c78-a551da7819b9",
   "metadata": {},
   "source": [
    "#### Multi-hop question\n",
    "\n",
    "This question requires that the agent perform multiple searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b3a0916-d8ca-4092-b91c-d9e2b05259d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': [FunctionMessage(content='[{\\'url\\': \\'https://en.wikipedia.org/wiki/Cookie_(cockatoo)\\', \\'content\\': \\'He was one of the longest-lived birds on record[4] and was recognised by the Guinness World Records as the oldest living parrot in the world.[5]\\\\nThe next-oldest pink cockatoo to be found in a zoological setting was a 31-year-old female bird located at Paradise Wildlife Sanctuary, England.[3] Information published by the World Parrot Trust states longevity for Cookie\\\\\\'s species in captivity is on average 40–60 years.[6]\\\\nLife[edit]\\\\nCookie was Brookfield Zoo\\\\\\'s oldest resident and the last surviving member of the animal collection from the time of the zoo\\\\\\'s opening in 1934, having arrived from Taronga Zoo of Sydney, New South Wales, Australia, in the same year and judged to be one year old at the time.[7]\\\\nIn the 1950s an attempt was made to introduce Cookie to a female pink cockatoo, but Cookie rejected her as \"she was not nice to him\".[8]\\\\n In 2007, Cookie was diagnosed with, and placed on medication and nutritional supplements for, osteoarthritis and osteoporosis\\\\xa0– medical conditions which occur commonly in aging animals and humans alike,[7] although it is believed that the latter may also have been brought on as a result of being fed a seed-only diet for the first 40 years of his life, in the years before the dietary requirements of his species were fully understood.[9]\\\\nCookie was \"retired\" from exhibition at the zoo in 2009 (following a few months of weekend-only appearances) in order to preserve his health, after it was noticed by staff that his appetite, demeanor and stress levels improved markedly when not on public display. age.[11] A memorial at the zoo was unveiled in September 2017.[12]\\\\nIn 2020, Cookie became the subject of a poetry collection by Barbara Gregorich entitled Cookie the Cockatoo: Everything Changes.[13]\\\\nSee also[edit]\\\\nReferences[edit]\\\\nExternal links[edit] He was believed to be the oldest member of his species alive in captivity, at the age of 82 in June 2015,[1][2] having significantly exceeded the average lifespan for his kind.[3] He was moved to a permanent residence in the keepers\\\\\\' office of the zoo\\\\\\'s Perching Bird House, although he made occasional appearances for special events, such as his birthday celebration, which was held each June.[3]\\'}]', additional_kwargs={'idx': 1, 'args': {'query': 'oldest parrot alive'}}, name='tavily_search_results_json', id='a660a43c-1cd5-4a0a-838d-6c48d633faaa'), FunctionMessage(content='[{\\'url\\': \\'https://www.thesprucepets.com/how-long-do-parrots-and-other-pet-birds-live-1238433\\', \\'content\\': \"It\\'s possible that a pet bird can outlive its owners\\\\nThe Spruce / Adrienne Legault\\\\nParrots and other birds can live up to 10 to 50 years or more depending on the type and the conditions they live in. They vary in size from small birds that can fit in the palm of your hand to large birds the size of a cat and their lifespans are just as variable.\\\\n Also, for birds who live longer some owners have to make a plan of where the bird is going in the circumstance the bird outlives the owner.\\\\n In reality, there is a wide range in the age that pet birds might reach and certainly, some will live longer (or shorter amounts of time) than the ages listed.\\\\n Potential owners need to be aware of the longevity of their bird so they can be prepared to provide proper care for them for as long as they live.\\\\n\"}]', additional_kwargs={'idx': 2, 'args': {'query': 'average lifespan of a parrot'}}, name='tavily_search_results_json', id='3bc3688f-cfa6-4ad2-b716-23bb20871c26'), FunctionMessage(content='join', additional_kwargs={'idx': 3, 'args': ()}, name='join', id='cbb0c810-4c29-4729-ba3c-6cd22997510f')]}\n",
      "---\n",
      "{'join': [AIMessage(content=\"Thought: The oldest parrot alive was Cookie, a cockatoo, who lived to be 82 years old. The average lifespan for Cookie's species in captivity is 40-60 years.\", id='5e280e14-3ce4-479e-bbfb-93d0dfa7dfd7'), AIMessage(content='The oldest parrot alive was Cookie, a cockatoo, who lived to be 82 years old. This is significantly longer than the average lifespan for his species, which is 40-60 years. Therefore, Cookie lived 22-42 years longer than the average.', id='076f8d25-c235-4fca-ab7e-df81f4d0cc4b')]}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "steps = chain.stream(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"What's the oldest parrot alive, and how much longer is that than the average?\"\n",
    "        )\n",
    "    ],\n",
    "    {\n",
    "        \"recursion_limit\": 100,\n",
    "    },\n",
    ")\n",
    "for step in steps:\n",
    "    print(step)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1bef992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': [FunctionMessage(content=\"[{'url': 'https://www.youtube.com/user/krishnaik06', 'content': 'This is my YouTube channel where I explain various topics on machine learning, deep learning, and AI with many real-world problem scenarios. ... I have delivered over 30 tech talks on data science ...'}]\", additional_kwargs={'idx': 1, 'args': {'query': 'krish naik recent youtube video on datascience'}}, name='tavily_search_results_json', id='1e2e14e7-5489-4e90-9335-e784486d69b5'), FunctionMessage(content='join', additional_kwargs={'idx': 2, 'args': ()}, name='join', id='b4560ee9-d3ad-4db9-af41-c5a828945ebd')]}\n",
      "---\n",
      "{'join': [AIMessage(content=\"Thought: The search result only provides general information about Krish Naik's YouTube channel but does not give specific details about the most recent video on data science.\", id='63977264-b2c1-415d-a996-ba666fce9d29'), SystemMessage(content='Context from last attempt: The search query did not return specific details about the recent video. A more targeted search query or a direct visit to the YouTube channel might be required.', id='d3476f39-35a2-4642-8b16-6d70661917ec')]}\n",
      "---\n",
      "{'plan_and_schedule': [FunctionMessage(content=\"[{'url': 'https://www.reddit.com/r/datascience/comments/11cydu8/thoughts_on_krish_naiks_course/', 'content': 'Hey! While browsing Reddit, I saw this Youtuber name Krish Naik mentioned various times, and how he has helped many people get a good understanding of Data Science and Machine Learning. In his 6-Month Data Science Roadmap video, he mentions a course he sells called Data Science Masters with a 7-8 month duration ($50), which goes over a lot of topics and it just started a month ago.'}]\", additional_kwargs={'idx': 3, 'args': {'query': 'recent youtube video by krish naik on datascience'}}, name='tavily_search_results_json', id='b6feb78f-f800-45de-a363-9f6da80db449'), FunctionMessage(content='join', additional_kwargs={'idx': 4, 'args': ()}, name='join', id='92474fed-6f8f-49d4-807e-143fa13bbfa4')]}\n",
      "---\n",
      "{'join': [AIMessage(content=\"Thought: The search results still do not provide specific information about the most recent YouTube video posted by Krish Naik on data science. They only discuss Krish Naik's general impact and offerings related to data science.\", id='1bf18649-1d19-4ce9-847f-e774973b2881'), SystemMessage(content=\"Context from last attempt: The searches did not yield the specific recent video information. A direct visit to Krish Naik's YouTube channel or a more precise query about recent uploads might be required.\", id='69cf1f58-1833-428f-84fb-f79e2502fead')]}\n",
      "---\n",
      "{'plan_and_schedule': []}\n",
      "---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m steps \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m      2\u001b[0m     [\n\u001b[1;32m      3\u001b[0m         HumanMessage(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     },\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(step)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/langgraph/langgraph/pregel/__init__.py:869\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    862\u001b[0m futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    863\u001b[0m     executor\u001b[38;5;241m.\u001b[39msubmit(run_with_retry, task, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy)\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m next_tasks\n\u001b[1;32m    865\u001b[0m ]\n\u001b[1;32m    867\u001b[0m \u001b[38;5;66;03m# execute tasks, and wait for one to fail or all to finish.\u001b[39;00m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# each task is independent from all other concurrent tasks\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m done, inflight \u001b[38;5;241m=\u001b[39m \u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIRST_EXCEPTION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m    876\u001b[0m _panic_or_proceed(done, inflight, step)\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/concurrent/futures/_base.py:307\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[1;32m    305\u001b[0m     waiter \u001b[38;5;241m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m f\u001b[38;5;241m.\u001b[39m_condition:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "steps = chain.stream(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"What's the recent youtube video posted by krish naik on datascience?\"\n",
    "        )\n",
    "    ],\n",
    "    {\n",
    "        \"recursion_limit\": 100,\n",
    "    },\n",
    ")\n",
    "for step in steps:\n",
    "    print(step)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c65c414-7668-4fdf-ba97-f42f659b1317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': [FunctionMessage(content='join', additional_kwargs={'idx': 1, 'args': ()}, name='join', id='5521ecbb-1cc1-4907-a55f-2ced84ec5d0f')]}\n",
      "---\n",
      "{'join': [AIMessage(content=\"Thought: I need to check the contents of the provided YouTube playlist to answer the user's question accurately.\", id='f72432f1-01e3-43a1-b185-85fae9280805'), SystemMessage(content='Context from last attempt: I need to extract and review the video titles and descriptions in the YouTube playlist to provide the required information.', id='385bdc6a-2d88-4f0a-8cc8-c780281bcf79')]}\n",
      "---\n",
      "DATA MODEL = video_url='https://www.youtube.com/playlist?list=PLYQsp-tXX9w6dCJBsgZfddg5pAuWXapU4' context=None\n",
      "{'plan_and_schedule': [FunctionMessage(content=\"{'url': 'https://www.youtube.com/playlist?list=PLYQsp-tXX9w6dCJBsgZfddg5pAuWXapU4', 'title': 'Sample Title', 'description': 'Sample description of the video.', 'views': '12345', 'likes': '678', 'dislikes': '90', 'comments': [{'author': 'User1', 'text': 'Sample comment 1'}, {'author': 'User2', 'text': 'Sample comment 2'}]}\", additional_kwargs={'idx': 2, 'args': {'video_url': 'https://www.youtube.com/playlist?list=PLYQsp-tXX9w6dCJBsgZfddg5pAuWXapU4'}}, name='youtube_parser', id='b54f3a3c-160a-4246-be5f-ccf4e95cbe96'), FunctionMessage(content='join', additional_kwargs={'idx': 3, 'args': ()}, name='join', id='03d96248-2723-4f00-a324-9670935bdb43')]}\n",
      "---\n",
      "{'join': [AIMessage(content='Thought: I have not gathered enough information from the provided YouTube playlist. I need to extract and review the video titles and descriptions in the playlist to provide the required information.', id='34550e50-7cbc-467c-af9d-4cddc3d577dc'), SystemMessage(content=\"Context from last attempt: The previous attempt did not yield the necessary details about the content of the YouTube playlist. I need to extract and review the video titles and descriptions to accurately answer the user's question.\", id='0c055188-d7f0-419e-93e0-3ba4484ac503')]}\n",
      "---\n",
      "DATA MODEL = video_url='https://www.youtube.com/playlist?list=PLYQsp-tXX9w6dCJBsgZfddg5pAuWXapU4' context=None\n",
      "{'plan_and_schedule': []}\n",
      "---\n",
      "{'join': [AIMessage(content='Thought: I was unable to retrieve specific information about the contents of the YouTube playlist beyond the sample data. The user needs detailed information about the video titles and descriptions in the playlist.', id='cfd3482e-0e5a-4f43-b916-61f315774b2f'), SystemMessage(content='Context from last attempt: I need to access and review the actual video titles and descriptions in the YouTube playlist to provide an accurate response.', id='7a43b513-9a18-469c-93ee-67a894964a1a')]}\n",
      "---\n",
      "DATA MODEL = video_url='https://www.youtube.com/playlist?list=PLYQsp-tXX9w6dCJBsgZfddg5pAuWXapU4' context=['Extract metadata and comments from the first video in the playlist.']\n",
      "{'plan_and_schedule': [FunctionMessage(content=\"{'url': 'https://www.youtube.com/playlist?list=PLYQsp-tXX9w6dCJBsgZfddg5pAuWXapU4', 'title': 'Sample Title', 'description': 'Sample description of the video.', 'views': '12345', 'likes': '678', 'dislikes': '90', 'comments': [{'author': 'User1', 'text': 'Sample comment 1'}, {'author': 'User2', 'text': 'Sample comment 2'}]}\", additional_kwargs={'idx': 4, 'args': {'video_url': 'https://www.youtube.com/playlist?list=PLYQsp-tXX9w6dCJBsgZfddg5pAuWXapU4'}}, name='youtube_parser', id='6ee84042-2bac-4ae6-a689-5153bae66d20'), FunctionMessage(content='join', additional_kwargs={'idx': 5, 'args': ()}, name='join', id='9cf79db7-475d-421a-9263-a016d69852de')]}\n",
      "---\n",
      "{'join': [AIMessage(content='Thought: I made several attempts to retrieve detailed information from the YouTube playlist but was only able to access sample data. The specific content of the playlist remains unknown.', id='2e45af8a-26d1-4238-8795-fad6b06880f9'), AIMessage(content=\"I attempted to gather detailed information from the YouTube playlist but was only able to access sample data. Unfortunately, I couldn't retrieve the actual titles and descriptions of the videos. You might need to check the playlist directly on YouTube for more details.\", id='e5aeb5c0-111f-4c52-9ebc-299e7300c6bd')]}\n",
      "---\n",
      "DATA MODEL = video_url='https://www.youtube.com/playlist?list=PLYQsp-tXX9w6dCJBsgZfddg5pAuWXapU4' context=None\n",
      "{'plan_and_schedule': []}\n",
      "---\n",
      "{'join': [AIMessage(content=\"Thought: I made several attempts to retrieve detailed information from the YouTube playlist but was only able to access sample data. Unfortunately, I couldn't retrieve the actual titles and descriptions of the videos. The user might need to check the playlist directly on YouTube for more details.\", id='0163a762-dc84-4ebe-8660-9ae1baa79978'), AIMessage(content=\"I attempted to gather detailed information from the YouTube playlist but was only able to access sample data. Unfortunately, I couldn't retrieve the actual titles and descriptions of the videos. You might need to check the playlist directly on YouTube for more details.\", id='a2dcf2ba-2b90-4312-b78b-81498318acea')]}\n",
      "---\n",
      "DATA MODEL = video_url='https://www.youtube.com/playlist?list=PLYQsp-tXX9w6dCJBsgZfddg5pAuWXapU4' context=None\n",
      "{'plan_and_schedule': []}\n",
      "---\n",
      "{'join': [AIMessage(content=\"Thought: I made several attempts to retrieve detailed information from the YouTube playlist but was only able to access sample data. Unfortunately, I couldn't retrieve the actual titles and descriptions of the videos. The user might need to check the playlist directly on YouTube for more details.\", id='1e4bd379-cbca-4788-962a-72d4856f18b3'), AIMessage(content=\"I attempted to gather detailed information from the YouTube playlist but was only able to access sample data. Unfortunately, I couldn't retrieve the actual titles and descriptions of the videos. You might need to check the playlist directly on YouTube for more details.\", id='ef5723a4-0eda-4509-ab79-3cc4a9e89d31')]}\n",
      "---\n",
      "{'plan_and_schedule': []}\n",
      "---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m steps \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m      2\u001b[0m     [\n\u001b[1;32m      3\u001b[0m         HumanMessage(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     },\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(step)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/langgraph/langgraph/pregel/__init__.py:869\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    862\u001b[0m futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    863\u001b[0m     executor\u001b[38;5;241m.\u001b[39msubmit(run_with_retry, task, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy)\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m next_tasks\n\u001b[1;32m    865\u001b[0m ]\n\u001b[1;32m    867\u001b[0m \u001b[38;5;66;03m# execute tasks, and wait for one to fail or all to finish.\u001b[39;00m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# each task is independent from all other concurrent tasks\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m done, inflight \u001b[38;5;241m=\u001b[39m \u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIRST_EXCEPTION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m    876\u001b[0m _panic_or_proceed(done, inflight, step)\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/concurrent/futures/_base.py:307\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[1;32m    305\u001b[0m     waiter \u001b[38;5;241m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m f\u001b[38;5;241m.\u001b[39m_condition:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "steps = chain.stream(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"What's mentioned in the youtube video https://www.youtube.com/playlist?list=PLYQsp-tXX9w6dCJBsgZfddg5pAuWXapU4\"\n",
    "        )\n",
    "    ],\n",
    "    {\n",
    "        \"recursion_limit\": 100,\n",
    "    },\n",
    ")\n",
    "for step in steps:\n",
    "    print(step)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b859bc7-1a85-4d35-b57b-f67c87282403",
   "metadata": {},
   "source": [
    "#### Multi-step  math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38d3ea91-59ba-4267-8060-ed75bbc840c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': [FunctionMessage(content='3307.0', additional_kwargs={'idx': 1, 'args': {'problem': '3*(4+5)/0.5 + 3245 + 8'}}, name='math', id='ea6b72b7-0e21-4ae1-bcec-288be7061d83'), FunctionMessage(content='7.565011820330969', additional_kwargs={'idx': 2, 'args': {'problem': '32/4.23'}}, name='math', id='ef240d3c-baee-4125-8f63-df462ea746b5'), FunctionMessage(content='3314.565011820331', additional_kwargs={'idx': 3, 'args': {'problem': 'sum of $1 and $2', 'context': ['$1', '$2']}}, name='math', id='cf7ff256-3012-4c60-b7b6-7451ff2cbd15'), FunctionMessage(content='join', additional_kwargs={'idx': 4, 'args': ()}, name='join', id='41e4745e-20f3-4227-8519-e69fe5e857df')]}\n",
      "> should_continue  STATE = [HumanMessage(content=\"What's ((3*(4+5)/0.5)+3245) + 8? What's 32/4.23? What's the sum of those two values?\", id='c0d5d967-cef5-4c82-be3d-4fe9cc347229'), FunctionMessage(content='3307.0', additional_kwargs={'idx': 1, 'args': {'problem': '3*(4+5)/0.5 + 3245 + 8'}}, name='math', id='ea6b72b7-0e21-4ae1-bcec-288be7061d83'), FunctionMessage(content='7.565011820330969', additional_kwargs={'idx': 2, 'args': {'problem': '32/4.23'}}, name='math', id='ef240d3c-baee-4125-8f63-df462ea746b5'), FunctionMessage(content='3314.565011820331', additional_kwargs={'idx': 3, 'args': {'problem': 'sum of $1 and $2', 'context': ['$1', '$2']}}, name='math', id='cf7ff256-3012-4c60-b7b6-7451ff2cbd15'), FunctionMessage(content='join', additional_kwargs={'idx': 4, 'args': ()}, name='join', id='41e4745e-20f3-4227-8519-e69fe5e857df'), AIMessage(content='Thought: The calculations were performed, and the results are as follows: ((3*(4+5)/0.5)+3245) + 8 = 3307.0, 32/4.23 = 7.565011820330969, and the sum of those two values is 3314.565011820331.', id='019d2ffe-9468-43a6-8824-05cbd697e32c'), AIMessage(content='The value of ((3*(4+5)/0.5)+3245) + 8 is 3307.0. The value of 32/4.23 is 7.565011820330969. The sum of those two values is 3314.565011820331.', id='46dc3b02-1762-41cd-a4d9-96e86f6db90f')]\n",
      "{'join': [AIMessage(content='Thought: The calculations were performed, and the results are as follows: ((3*(4+5)/0.5)+3245) + 8 = 3307.0, 32/4.23 = 7.565011820330969, and the sum of those two values is 3314.565011820331.', id='019d2ffe-9468-43a6-8824-05cbd697e32c'), AIMessage(content='The value of ((3*(4+5)/0.5)+3245) + 8 is 3307.0. The value of 32/4.23 is 7.565011820330969. The sum of those two values is 3314.565011820331.', id='46dc3b02-1762-41cd-a4d9-96e86f6db90f')]}\n"
     ]
    }
   ],
   "source": [
    "for step in chain.stream(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"What's ((3*(4+5)/0.5)+3245) + 8? What's 32/4.23? What's the sum of those two values?\"\n",
    "        )\n",
    "    ]\n",
    "):\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6cf5fe0-f178-4197-950f-257711bff8d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of ((3*(4+5)/0.5)+3245) + 8 is 3307.0. The value of 32/4.23 is 7.565011820330969. The sum of those two values is 3314.565011820331.\n"
     ]
    }
   ],
   "source": [
    "# Final answer\n",
    "print(step[\"join\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c647d5f3-5e00-4449-9cec-5a9f438c9cff",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congrats on building your first LLMCompiler agent! I'll leave you with some known limitations to the implementation above:\n",
    "\n",
    "1. The planner output parsing format is fragile if your function requires more than 1 or 2 arguments. We could make it more robust by using streaming tool calling.\n",
    "2. Variable substitution is fragile in the example above. It could be made more robust by using a fine-tuned model and a more robust syntax (using e.g., Lark or a tool calling schema)\n",
    "3. The state can grow quite long if you require multiple re-planning runs. To handle, you could add a message compressor once you go above a certain token limit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431217e6-4c00-409f-a2bd-40ebff902489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
